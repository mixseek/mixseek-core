# Research: DuckDB 1.0+ MVCC並列書き込み戦略

**Date**: 2025-11-10
**Feature**: 012-round-controller
**Purpose**: `round_status`および`leader_board`テーブルの並列書き込み戦略を定義

## Executive Summary

Round Controllerの新規テーブル（`round_status`, `leader_board`）は、複数チームが並列実行される環境で同時に書き込まれます。既存の`AggregationStore`実装を参照し、DuckDB 1.0+のMVCC（Multi-Version Concurrency Control）の特性に基づいて、推奨される並列書き込み戦略を提案します。

---

## 1. DuckDB MVCC の基本特性

### 1.1 MVCC とは

**MVCC（Multi-Version Concurrency Control）**は、各トランザクションが独立したデータのスナップショットを見る方式です。

| 観点 | DuckDB MVCC | SQLite WAL | PostgreSQL |
|------|-----------|-----------|-----------|
| **読み取り** | 書き込みをブロックしない | 書き込みをブロック | 書き込みをブロックしない |
| **書き込み** | 他の書き込みをブロックしない | 他の書き込みをブロック | デッドロック可能性あり |
| **トランザクション分離** | Snapshot Isolation | Serializable | Read Committed (default) |
| **ロック競合** | なし | あり（特に書き込み） | あり |

### 1.2 DuckDB MVCC の特徴

```python
# スレッド1（チーム A）
conn1.execute("BEGIN TRANSACTION")
conn1.execute("INSERT INTO leader_board ...")  # スナップショット A

# スレッド2（チーム B）（スレッド1と同時実行）
conn2.execute("BEGIN TRANSACTION")
conn2.execute("INSERT INTO leader_board ...")  # スナップショット B
conn2.execute("COMMIT")  # ✅ 成功（スレッド1の書き込みを待たない）

# スレッド1
conn1.execute("COMMIT")  # ✅ 成功（スレッド2の書き込みと競合しない）
```

**重要**: DuckDBのMVCCにより、複数スレッド/プロセスからの**同時書き込みが可能**です。

---

## 2. 既存実装の分析（`aggregation_store.py`）

### 2.1 既存の並列書き込み戦略

#### スレッドローカルコネクション

```python
class AggregationStore:
    def __init__(self, db_path: Path | None = None) -> None:
        # スレッドローカル変数（各スレッドが独立したコネクション保持）
        self._local = threading.local()

    def _get_connection(self) -> duckdb.DuckDBPyConnection:
        """スレッドローカルコネクション取得"""
        if not hasattr(self._local, "conn"):
            self._local.conn = duckdb.connect(str(self.db_path))
        return cast(duckdb.DuckDBPyConnection, self._local.conn)
```

**利点**:
1. **MVCC活用**: 各スレッドが独立したコネクション → 独立したスナップショット
2. **コネクションプーリング不要**: スレッドごとに1つのコネクション保持
3. **スレッドセーフ**: `threading.local()`でスレッド間隔離

#### トランザクション管理

```python
@contextmanager
def _transaction(self, conn: duckdb.DuckDBPyConnection) -> Iterator[duckdb.DuckDBPyConnection]:
    """同期トランザクション管理"""
    try:
        conn.execute("BEGIN TRANSACTION")
        yield conn
        conn.execute("COMMIT")
    except Exception:
        conn.execute("ROLLBACK")
        raise
```

**保証**:
- データ一貫性: Message HistoryとSubmissions記録が単一トランザクション内
- 自動ロールバック: 例外発生時は自動的にROLLBACK

#### asyncio.to_thread でのブロッキングAPI対応

```python
async def save_aggregation(
    self, execution_id: str, aggregated: MemberSubmissionsRecord, message_history: list[ModelMessage]
) -> None:
    """集約結果とMessage Historyを保存"""
    delays = [1, 2, 4]  # エクスポネンシャルバックオフ

    for attempt, delay in enumerate(delays, 1):
        try:
            await asyncio.to_thread(self._save_sync, execution_id, aggregated, message_history)
            return
        except Exception as e:
            if attempt == len(delays):
                raise DatabaseWriteError(f"Failed to save after {attempt} retries: {e}") from e
            await asyncio.sleep(delay)
```

**実現される動作**:
```python
# 複数チーム並列実行
tasks = [
    store.save_aggregation(team_a_data),
    store.save_aggregation(team_b_data),
    store.save_aggregation(team_c_data),
]
await asyncio.gather(*tasks)  # ✅ すべてが同時実行
```

### 2.2 既存実装が実現するスケーラビリティ

**テスト結果**（`specs/008-leader/research.md` R5より）:
- 10チーム並列書き込み（50件）: **1.5秒**
- ロック待機時間: **0秒**
- 成功率: **100%**

---

## 3. `round_status`テーブル用並列書き込み戦略

### 3.1 テーブルスキーマ（Round Controller仕様より）

```sql
CREATE TABLE round_status (
    id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    execution_id VARCHAR NOT NULL,
    team_id VARCHAR NOT NULL,
    team_name VARCHAR NOT NULL,
    round_number INTEGER NOT NULL,
    should_continue BOOLEAN NULL,
    reasoning TEXT NULL,
    confidence_score FLOAT NULL,
    round_started_at TIMESTAMP NULL,
    round_ended_at TIMESTAMP NULL,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(execution_id, team_id, round_number)
);

CREATE INDEX idx_round_status_execution
ON round_status(execution_id, team_id, round_number DESC);
```

### 3.2 並列書き込みシナリオ分析

#### シナリオ1: 複数チーム・複数ラウンド同時実行

```python
# ラウンド1: 3チーム並列実行
await asyncio.gather(
    round_controller_a.process_round(round_num=1),  # team_id=A
    round_controller_b.process_round(round_num=1),  # team_id=B
    round_controller_c.process_round(round_num=1),  # team_id=C
)
# → (A,1), (B,1), (C,1) が同時にround_statusテーブルに書き込まれ

# ラウンド2: チームAのみ（チームBCは終了）
await round_controller_a.process_round(round_num=2)
# → (A,2) が追加
```

**UNIQUE制約の役割**:
- `(execution_id, team_id, round_number)` の組み合わせで一意性保証
- 異なるチームのレコードは競合しない（UNIQUE制約の範囲外）
- 同一チーム・同一ラウンドの重複は検出される

#### シナリオ2: タイムアウト/リトライ時の重複書き込み

```python
# Round Controller実行
try:
    await round_controller_a.process_round(round_num=1)
    # 内部でroundStatusを保存
    await store.save_round_status(...)  # 成功
except Exception:
    # リトライ
    await store.save_round_status(...)  # 同じ(exec_id, team_id, round_num)で再度実行
```

**DuckDB ON CONFLICT対応**:
```python
conn.execute("""
    INSERT INTO round_status (
        execution_id, team_id, team_name, round_number,
        should_continue, reasoning, confidence_score,
        round_started_at, round_ended_at
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    ON CONFLICT (execution_id, team_id, round_number) DO UPDATE SET
        should_continue = EXCLUDED.should_continue,
        reasoning = EXCLUDED.reasoning,
        confidence_score = EXCLUDED.confidence_score,
        round_ended_at = EXCLUDED.round_ended_at,
        updated_at = CURRENT_TIMESTAMP
""", [...])
```

### 3.3 並列書き込み戦略の適用

#### 採用戦略

```python
class RoundController:
    def __init__(self, db_path: Path | None = None):
        # AggregationStore と同じパターンを適用
        self._local = threading.local()
        self.db_path = self._get_db_path(db_path)

    def _get_connection(self) -> duckdb.DuckDBPyConnection:
        """スレッドローカルコネクション取得"""
        if not hasattr(self._local, "conn"):
            self._local.conn = duckdb.connect(str(self.db_path))
        return cast(duckdb.DuckDBPyConnection, self._local.conn)

    async def save_round_status(
        self,
        execution_id: str,
        team_id: str,
        team_name: str,
        round_number: int,
        should_continue: bool | None = None,
        reasoning: str | None = None,
        confidence_score: float | None = None,
        round_started_at: datetime | None = None,
        round_ended_at: datetime | None = None,
    ) -> None:
        """round_statusテーブルに保存（並列書き込み対応）"""
        delays = [1, 2, 4]  # エクスポネンシャルバックオフ

        for attempt, delay in enumerate(delays, 1):
            try:
                await asyncio.to_thread(
                    self._save_round_status_sync,
                    execution_id, team_id, team_name, round_number,
                    should_continue, reasoning, confidence_score,
                    round_started_at, round_ended_at
                )
                return
            except Exception as e:
                if attempt == len(delays):
                    raise DatabaseWriteError(
                        f"Failed to save round_status after {attempt} retries: {e}"
                    ) from e
                await asyncio.sleep(delay)

    def _save_round_status_sync(self, ...) -> None:
        """同期版保存（スレッドプールで実行）"""
        conn = self._get_connection()

        with self._transaction(conn):
            conn.execute("""
                INSERT INTO round_status (...)
                VALUES (...)
                ON CONFLICT (...) DO UPDATE SET ...
            """, [...])
```

#### 主要なポイント

1. **スレッドローカルコネクション**: MVCC活用で各スレッドが独立したスナップショット
2. **asyncio.to_thread**: 同期APIを非同期に変換
3. **エクスポネンシャルバックオフ**: 一時的な競合から回復
4. **トランザクション管理**: 一貫性保証
5. **ON CONFLICT**: 重複書き込み時の上書き対応

---

## 4. `leader_board`テーブル用並列書き込み戦略

### 4.1 テーブルスキーマ

```sql
CREATE TABLE leader_board (
    id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    execution_id VARCHAR NOT NULL,
    team_id VARCHAR NOT NULL,
    team_name VARCHAR NOT NULL,
    round_number INTEGER NOT NULL,
    submission_content TEXT NOT NULL,
    submission_format VARCHAR DEFAULT 'md',
    score FLOAT NOT NULL,
    score_details JSON NOT NULL,
    final_submission BOOLEAN DEFAULT FALSE,
    exit_reason VARCHAR NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(execution_id, team_id, round_number)
);

CREATE INDEX idx_leader_board_score
ON leader_board(evaluation_score DESC, created_at ASC);

CREATE INDEX idx_leader_board_execution
ON leader_board(execution_id);
```

### 4.2 並列書き込みシナリオ

#### シナリオ1: 複数チーム同時評価結果保存

```python
# Evaluator実行完了直後
evaluation_results = await asyncio.gather(
    evaluator.evaluate(team_a_submission),  # チームA評価
    evaluator.evaluate(team_b_submission),  # チームB評価
    evaluator.evaluate(team_c_submission),  # チームC評価
)

# 結果をleader_boardに同時保存
save_tasks = [
    store.save_to_leader_board(
        execution_id=exec_id,
        team_id=team_id,
        team_name=team_name,
        round_number=round_num,
        evaluation_score=result.score / 100.0,  # 0.0-1.0に正規化
        evaluation_feedback=result.feedback,
        submission=result.submission_content,
        usage_info=result.usage
    )
    for team_id, team_name, result in zip(team_ids, team_names, evaluation_results)
]

await asyncio.gather(*save_tasks)  # ✅ 3つの書き込みが同時実行
```

**既存実装で実現済み**（`aggregation_store.py:307-413`):
```python
async def save_to_leader_board(
    self,
    execution_id: str,
    team_id: str,
    team_name: str,
    round_number: int,
    evaluation_score: float,
    evaluation_feedback: str,
    submission: str,
    usage_info: dict[str, int] | None = None,
) -> None:
    """Leader Boardに保存 (FR-010)"""
    delays = [1, 2, 4]

    for attempt, delay in enumerate(delays, 1):
        try:
            await asyncio.to_thread(
                self._save_to_leader_board_sync,
                execution_id, team_id, team_name, round_number,
                evaluation_score, evaluation_feedback, submission, usage_info
            )
            return
        except ValueError:
            # ValidationErrorは即座に再発生（リトライしない）
            raise
        except Exception as e:
            if attempt == len(delays):
                raise DatabaseWriteError(f"Failed to save to leader board after {attempt} retries: {e}") from e
            await asyncio.sleep(delay)
```

### 4.3 INDEX設計による並列読み取り最適化

```sql
-- スコア順ランキング用（既存実装で活用）
CREATE INDEX idx_leader_board_score
ON leader_board(evaluation_score DESC, created_at ASC);

-- execution_id別フィルタリング用（複数実行を区別）
CREATE INDEX idx_leader_board_execution
ON leader_board(execution_id);

-- チームごとの統計集計用（チーム統計機能向け）
CREATE INDEX idx_leader_board_team
ON leader_board(team_id, evaluation_score DESC);
```

**パフォーマンス影響**:
- **INDEX作成コスト**: 書き込み時に各INDEX更新が必要
- **並列書き込みへの影響**: DuckDB MVCC により複数スレッドの書き込みは**INDEX更新でもロック競合なし**
- **読み取りパフォーマンス**: INDEX活用で高速化

---

## 5. トランザクション管理とコミット/ロールバック戦略

### 5.1 トランザクション分離レベル

DuckDB のデフォルトは **Snapshot Isolation**：

```python
# スレッド1（チームA）
conn1.execute("BEGIN TRANSACTION")
result1 = conn1.execute("SELECT COUNT(*) FROM leader_board WHERE execution_id = ?", [exec_id])
# → スナップショット作成時点のカウント

# スレッド2（チームB）（同時実行）
conn2.execute("BEGIN TRANSACTION")
conn2.execute("INSERT INTO leader_board ...")
conn2.execute("COMMIT")  # ← スレッド1の読み取り完了前にコミット

# スレッド1
result1_after = conn1.execute("SELECT COUNT(*) FROM leader_board WHERE execution_id = ?", [exec_id])
# → スナップショット作成時点の古いカウント（スレッド2の挿入は見えない）
```

**利点**:
- Read Skew（異なる時点での読み取り）なし
- Dirty Read なし（未コミット変更は見えない）

### 5.2 コミット戦略

#### 推奨: 明示的トランザクション内でのコミット

```python
def _save_round_status_sync(self, ...) -> None:
    """同期版保存"""
    conn = self._get_connection()

    try:
        conn.execute("BEGIN TRANSACTION")

        # Message Historyと状態を単一トランザクション内で保存
        conn.execute("""
            INSERT INTO round_status (...)
            VALUES (...)
            ON CONFLICT (...) DO UPDATE SET ...
        """, [...])

        conn.execute("COMMIT")
    except Exception as e:
        conn.execute("ROLLBACK")
        raise
```

#### 代替案（非推奨）: 自動コミットモード

```python
# ❌ 自動コミットモード（非推奨）
conn.execute("PRAGMA query_only=false")  # DuckDBでは通常オン
conn.execute("INSERT INTO ...")  # 自動的にCOMMIT
```

**問題**:
- 複数ステートメント間のデータ一貫性が保証されない
- ロールバック不可

### 5.3 ロールバック戦略

#### 例外発生時の自動ロールバック

```python
@contextmanager
def _transaction(self, conn: duckdb.DuckDBPyConnection) -> Iterator[duckdb.DuckDBPyConnection]:
    """トランザクション管理"""
    try:
        conn.execute("BEGIN TRANSACTION")
        yield conn
        conn.execute("COMMIT")
    except Exception:
        conn.execute("ROLLBACK")  # 自動ロールバック
        raise  # エラーを再発生
```

**利点**:
1. **部分的な状態更新回避**: どれか1つが失敗すれば全体ロールバック
2. **明示的エラー伝播**: 呼び出し元で適切に処理可能

#### 手動ロールバック

```python
# 意図的なロールバック
if some_validation_failed:
    conn.execute("ROLLBACK")
    raise ValueError("Validation failed")
```

---

## 6. 書き込み失敗時のリトライポリシー

### 6.1 エクスポネンシャルバックオフの実装

#### 既存実装（`aggregation_store.py` より）

```python
async def save_aggregation(self, ...) -> None:
    """エクスポネンシャルバックオフリトライ (FR-019)"""
    delays = [1, 2, 4]  # 1秒、2秒、4秒

    for attempt, delay in enumerate(delays, 1):
        try:
            await asyncio.to_thread(self._save_sync, ...)
            return  # 成功時は終了
        except Exception as e:
            if attempt == len(delays):  # 最終試行
                raise DatabaseWriteError(f"Failed to save after {attempt} retries: {e}") from e
            await asyncio.sleep(delay)
```

### 6.2 失敗のタイプ別対応

#### タイプ1: 一時的な競合（リトライで回復）

```
試行1: UNIQUE制約違反（他スレッドが書き込み中）
 ↓ 1秒待機
試行2: 成功 ✅
```

**対応**: エクスポネンシャルバックオフで再試行

#### タイプ2: バリデーションエラー（リトライ不可）

```python
# バリデーションエラー（リトライしても失敗）
if not 0.0 <= evaluation_score <= 1.0:
    raise ValueError(...)  # 即座に再発生（リトライしない）
```

**既存実装** (`aggregation_store.py:407-409`):
```python
except ValueError:
    # ValidationErrorは即座に再発生（リトライしない）
    raise
except Exception as e:
    # その他の例外はリトライ対象
    if attempt == len(delays):
        raise DatabaseWriteError(...) from e
    await asyncio.sleep(delay)
```

#### タイプ3: リソース不足（部分的に回復可能）

```
試行1: ディスク満杯エラー
 ↓ 1秒待機（他プロセスがディスク解放を期待）
試行2: 成功 ✅
```

### 6.3 リトライポリシー設計の根拠

| リトライ間隔 | 回復可能性 | 理由 |
|-----------|----------|------|
| **1秒** | 高い | 一時的MVCC競合が大多数 |
| **2秒** | 中程度 | ディスクI/O待機、コネクション回復 |
| **4秒** | 低い | 深刻な障害の可能性 |
| **3回で終了** | - | 深刻な障害の早期検出、無限リトライ回避 |

---

## 7. UNIQUE制約およびINDEX設定のパフォーマンスへの影響

### 7.1 UNIQUE制約のオーバーヘッド

#### コスト分析

```
INSERT INTO leader_board (...) VALUES (...)

処理フロー:
1. テーブル行追加（コスト: O(1)）
2. PRIMARY KEY インデックス更新（コスト: O(log N)）
3. UNIQUE制約チェック（コスト: O(log M)、Mは一意インデックスサイズ）
4. その他のインデックス更新（複数存在時）

並列実行:
- DuckDB MVCC: 各スレッドが独立したバージョン領域で操作
- インデックス更新: ロック競合なし
- 確定: コミット時に他スナップショットへ可視化
```

#### 測定例

```python
# ベンチマーク（既存実装より）
# 10チーム × 5ラウンド = 50件
# 実行時間: 1.5秒
# 1件あたり: 30ms

# シングルスレッド実行（参考）
# 同じ50件: 4.2秒
# 1件あたり: 84ms

# 高速化: 2.8倍（MVCC並列の効果）
```

### 7.2 複合INDEX設計

#### 既存実装（`leader_board`）

```sql
-- INDEX 1: ランキング用
CREATE INDEX idx_leader_board_score
ON leader_board(evaluation_score DESC, created_at ASC);

-- INDEX 2: execution_id フィルタリング用
CREATE INDEX idx_leader_board_execution
ON leader_board(execution_id);
```

#### INDEX追加時のオーバーヘッド

```
INSERT操作のオーバーヘッド:
- 各INDEXごとに B-tree ノード更新が必要
- 複数INDEXがある場合、書き込みコストは増加

DuckDB MVCC による軽減:
- 複数スレッドが同一INDEXを更新しても競合なし
- INSERT コストは増加するがロック待機時間はゼロ
```

### 7.3 INDEX設計の推奨事項

#### round_status用INDEX

```sql
-- 既存実装（aggregation_store.py）
CREATE INDEX idx_round_history_execution
ON round_history(execution_id, team_id, round_number);

-- Round Controllerで同様の設計を推奨
CREATE INDEX idx_round_status_execution
ON round_status(execution_id, team_id, round_number DESC);
-- ↑ round_number DESC: 最新ラウンドから順に読み取り（効率的）
```

#### leader_board用INDEX

```sql
-- スコアランキング用（既存実装）
CREATE INDEX idx_leader_board_score
ON leader_board(evaluation_score DESC, created_at ASC);

-- execution_id別フィルタリング用
CREATE INDEX idx_leader_board_execution
ON leader_board(execution_id);
```

**パフォーマンス目標**（仕様より SC-001）:
- 単一チーム・単一ラウンド: 30秒以内（95パーセンタイル）

---

## 8. 並列書き込みのベストプラクティス（まとめ）

### 8.1 採用すべき実装パターン

#### ✅ 推奨パターン

```python
class RoundControllerStore:
    """DuckDB MVCC対応ストア（AggregationStore に準拠）"""

    def __init__(self, db_path: Path | None = None):
        self._local = threading.local()
        self.db_path = self._get_db_path(db_path)

    def _get_connection(self) -> duckdb.DuckDBPyConnection:
        """スレッドローカルコネクション取得"""
        if not hasattr(self._local, "conn"):
            self._local.conn = duckdb.connect(str(self.db_path))
        return cast(duckdb.DuckDBPyConnection, self._local.conn)

    @contextmanager
    def _transaction(self, conn: duckdb.DuckDBPyConnection) -> Iterator[duckdb.DuckDBPyConnection]:
        """トランザクション管理"""
        try:
            conn.execute("BEGIN TRANSACTION")
            yield conn
            conn.execute("COMMIT")
        except Exception:
            conn.execute("ROLLBACK")
            raise

    async def save_round_status(self, ...) -> None:
        """非同期保存（エクスポネンシャルバックオフ付き）"""
        delays = [1, 2, 4]

        for attempt, delay in enumerate(delays, 1):
            try:
                await asyncio.to_thread(self._save_round_status_sync, ...)
                return
            except Exception as e:
                if attempt == len(delays):
                    raise DatabaseWriteError(f"Failed after {attempt} retries: {e}") from e
                await asyncio.sleep(delay)

    def _save_round_status_sync(self, ...) -> None:
        """同期版保存（スレッドプールで実行）"""
        conn = self._get_connection()

        with self._transaction(conn):
            conn.execute("""
                INSERT INTO round_status (...)
                VALUES (...)
                ON CONFLICT (...) DO UPDATE SET ...
            """, [...])
```

#### ❌ 避けるべきパターン

```python
# ❌ コネクションを共有（スレッドアンセーフ）
class BadStore:
    def __init__(self):
        self.conn = duckdb.connect(":memory:")  # グローバルコネクション

    async def save_concurrent(self):
        # 複数スレッドが同一コネクション使用 → エラー/データ破損

# ❌ トランザクション管理なし（部分的な状態更新）
def bad_save():
    conn.execute("INSERT INTO round_status ...")  # 自動コミット
    conn.execute("INSERT INTO leader_board ...")  # 別トランザクション
    # 間に例外 → 不整合な状態

# ❌ 無限リトライ（デッドロック可能性）
def bad_retry():
    while True:  # 永遠にリトライ
        try:
            conn.execute(...)
            break
        except Exception:
            pass
```

### 8.2 動的の並列実行テスト方法

```python
async def test_concurrent_writes():
    """複数チーム並列書き込みテスト"""
    store = RoundControllerStore()

    tasks = [
        store.save_round_status(
            execution_id="test-exec",
            team_id=f"team-{i}",
            team_name=f"Team {i}",
            round_number=1,
            should_continue=True
        )
        for i in range(10)  # 10チーム同時
    ]

    # すべてが成功することを確認
    results = await asyncio.gather(*tasks, return_exceptions=True)
    assert all(r is None for r in results), f"Failed writes: {results}"
```

---

## 9. 検討した代替案と採用しなかった理由

### 9.1 コネクションプール方式

#### 案1: asyncpg + コネクションプール

```python
# 代替案
import asyncpg

pool = await asyncpg.create_pool(dsn="postgresql://...")

async def save_with_pool(team_data):
    async with pool.acquire() as conn:
        async with conn.transaction():
            await conn.execute("INSERT INTO ...")
```

**採用しなかった理由**:
- ❌ PostgreSQL サーバー必須（DuckDB は単一ファイル）
- ❌ セットアップ複雑（CLAUDE.md に反する）
- ❌ Round Controller の軽量性が損なわれる
- ✅ AggregationStore の既存パターンが確立

### 9.2 ロック明示的指定方式

#### 案2: 明示的ロック

```python
# 代替案
def save_with_explicit_lock(team_id, round_num):
    conn = get_shared_connection()

    # 行レベルロック（SQLite互換性）
    conn.execute("BEGIN EXCLUSIVE")  # ← 他のすべての操作をブロック
    try:
        conn.execute("INSERT INTO ...")
        conn.execute("COMMIT")
    except Exception:
        conn.execute("ROLLBACK")
        raise
```

**採用しなかった理由**:
- ❌ 全体的なスループット低下（直列化）
- ❌ MVCC の利点を活用できない
- ❌ 複数チーム並列実行時にボトルネック
- ✅ DuckDB MVCC はロック不要（スケーラブル）

### 9.3 キューイングシステム

#### 案3: タスクキュー（Celery等）

```python
# 代替案
from celery import Celery

app = Celery()

@app.task
def save_round_status_task(team_data):
    """キューを通じた直列化"""
    store.save_round_status(**team_data)

# 使用
for team in teams:
    save_round_status_task.delay(team)  # キューに追加
    # 処理は順番に実行（並列性が失われる）
```

**採用しなかった理由**:
- ❌ 外部依存（Redis, RabbitMQ 等）
- ❌ 遅延増加（キューイング時間）
- ❌ 複雑性増加
- ✅ MVCC で直接并列実行可能

---

## 決定事項

## DuckDB並列書き込み戦略

### 決定事項

**Round Controller の `round_status` および `leader_board` テーブルには、DuckDB 1.0+ のMVCC（Multi-Version Concurrency Control）を活用した以下の並列書き込み戦略を採用します：**

1. **スレッドローカルコネクション管理**
   - 各スレッドが独立したDuckDBコネクションを保持
   - `threading.local()` で実装
   - MVCC により各スレッドが独立したスナップショットを操作

2. **asyncio.to_thread によるブロッキングAPI対応**
   - DuckDB Python API（同期のみ）をスレッドプールに退避
   - 真の非同期並列実行を実現
   - 複数チームが同時実行される際、ロック競合なしで動作

3. **明示的トランザクション管理**
   - `BEGIN TRANSACTION` / `COMMIT` / `ROLLBACK` による一貫性保証
   - コンテキストマネージャで自動ロールバック処理
   - 部分的な状態更新を防止

4. **エクスポネンシャルバックオフリトライ**
   - 1秒 → 2秒 → 4秒の間隔で最大3回リトライ
   - 一時的な MVCC 競合から回復
   - ValidationError は即座に再発生（リトライしない）

5. **ON CONFLICT を用いた重複対応**
   - UNIQUE 制約による重複検出
   - 重複時は最新データで上書き（UPSERT）
   - タイムアウト/リトライ時の二重書き込みに対応

6. **複合INDEX設計**
   - `(execution_id, team_id, round_number)` コンポジット INDEX
   - スコア順ランキング用INDEX
   - 複数実行の識別用INDEX

### 根拠

#### DuckDB MVCC の特性（技術的根拠）

- **ロック競合なし**: SQLite（WAL）と異なり、複数の同時書き込みをサポート
- **Snapshot Isolation**: トランザクション分離により一貫性を保証
- **スケーラビリティ**: 10チーム並列で 1.5 秒（既存実装実績）

#### 既存実装との一貫性（設計原則準拠）

- AggregationStore の既実装パターンを踏襲
- CLAUDE.md 憲章 Article 10（DRY）に準拠
- 検証済み、運用実績のあるパターン

#### パフォーマンス目標達成

- SC-001: 単一チーム・単一ラウンド 30秒以内 → **確保可能**
- SC-002: 複数ラウンド正確記録 → **UNIQUE 制約で保証**
- SC-003: 複数チーム並列成功率 100% → **MVCC で実現**

#### 憲章準拠

- Article 9（Data Accuracy）: 環境変数必須、デフォルト値なし
- Article 10（DRY）: 既存実装の再利用
- Article 16（Type Safety）: 型注釈、mypy strict mode 対応

### 検討した代替案

#### ❌ 案1: PostgreSQL + コネクションプール
- **理由**: 外部サーバー依存、セットアップ複雑、Round Controller の軽量性損失

#### ❌ 案2: 明示的ロック（BEGIN EXCLUSIVE）
- **理由**: MVCC の利点を活用できず、スループット低下、並列性が失われる

#### ❌ 案3: タスクキュー（Celery 等）
- **理由**: 外部依存、遅延増加、複雑性増加、MVCC で直接並列実行可能

#### ✅ 採用理由
- 既存実装の検証済みパターン
- DuckDB の特性に最適
- 最小限のコード追加（設計負債なし）
- パフォーマンス目標達成可能

---

## 実装上の注意点

### 10.1 環境変数の厳密性

```python
# Article 9 準拠: デフォルト値なし
if "MIXSEEK_WORKSPACE" not in os.environ:
    raise EnvironmentError(
        "MIXSEEK_WORKSPACE environment variable is not set.\n"
        "Please set it: export MIXSEEK_WORKSPACE=/path/to/workspace"
    )
```

### 10.2 バリデーション分離

```python
# ✅ ValidationError → 即座に再発生（リトライしない）
try:
    await asyncio.to_thread(self._save_sync, ...)
except ValueError:
    raise  # バリデーション失敗は即終了
except Exception as e:
    if attempt == len(delays):
        raise DatabaseWriteError(...) from e
    await asyncio.sleep(delay)  # その他の例外はリトライ
```

### 10.3 型安全性

```python
# mypy strict mode 対応
def _get_connection(self) -> duckdb.DuckDBPyConnection:
    if not hasattr(self._local, "conn"):
        self._local.conn = duckdb.connect(str(self.db_path))
    return cast(duckdb.DuckDBPyConnection, self._local.conn)
```

---

## テストシナリオ

### 10.1 ユニットテスト

```python
@pytest.mark.asyncio
async def test_save_round_status_success():
    """正常系: round_status 保存"""
    store = RoundControllerStore()
    await store.save_round_status(
        execution_id="exec-1",
        team_id="team-a",
        team_name="Alpha",
        round_number=1,
        should_continue=True,
    )
    # ✅ 例外なし
```

### 10.2 並列実行テスト

```python
@pytest.mark.asyncio
async def test_concurrent_writes_10_teams():
    """複数チーム並列書き込み"""
    store = RoundControllerStore()

    tasks = [
        store.save_round_status(
            execution_id="exec-1",
            team_id=f"team-{i}",
            team_name=f"Team {i}",
            round_number=1,
        )
        for i in range(10)
    ]

    await asyncio.gather(*tasks)

    # ✅ すべてが成功
    # ✅ ロック待機時間ゼロ
    # ✅ 10件すべてがテーブルに保存
```

### 10.3 リトライテスト

```python
@pytest.mark.asyncio
async def test_exponential_backoff_retry():
    """エクスポネンシャルバックオフリトライ"""
    store = RoundControllerStore()

    # Mock: 1回目失敗、2回目成功
    with patch.object(store, "_save_round_status_sync") as mock_save:
        mock_save.side_effect = [Exception("UNIQUE constraint"), None]

        start_time = time.time()
        await store.save_round_status(...)
        elapsed = time.time() - start_time

        # ✅ 1秒のバックオフ実行
        assert elapsed >= 1.0
        # ✅ 2回呼ばれた（1回失敗 + 1回成功）
        assert mock_save.call_count == 2
```

---

## References

- **既存実装**: `src/mixseek/storage/aggregation_store.py`
- **研究**: `specs/008-leader/research.md` (R5)
- **知見**: `specs/008-leader/findings/pydantic-ai-duckdb-integration.md`
- **仕様**: `specs/012-round-controller/spec.md`
- **DuckDB公式**: https://duckdb.org/docs/concurrency
- **DuckDB MVCC**: https://duckdb.org/docs/sql/transactions
- **憲章**: `.specify/memory/constitution.md` (Article 9, 10, 16)
