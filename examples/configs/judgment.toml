# MixSeek Judgment Configuration
# Generated by: mixseek config init --component judgment

# LLM model for improvement judgment
# Format: "provider:model-name" (e.g., "google-gla:gemini-2.5-flash")
model = "google-gla:gemini-2.5-flash"

# Temperature for LLM calls (0.0 = deterministic, recommended for judgment)
temperature = 0.0

# Maximum retry attempts for API calls
max_retries = 3

# Timeout in seconds for judgment API calls
timeout_seconds = 60

# Optional: Custom system instruction (leave commented to use default)
# system_instruction = """
# Your custom instruction here...
# """
